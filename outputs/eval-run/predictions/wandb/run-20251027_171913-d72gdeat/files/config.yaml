_wandb:
    value:
        cli_version: 0.22.2
        e:
            feb93dq0mu5k5l2hgrl75zhatm8zbq1v:
                args:
                    - experiment=flow_multi/dataset_20k_40k
                    - ckpt_path=./logs/dataset_20k_40k-2025-10-24_12-59-16/checkpoints/last.ckpt
                    - mode=predict
                    - callbacks=prediction_writer
                    - paths=default
                    - paths.output_dir=./outputs/eval-run/predictions
                    - data.predict_file=test.h5
                    - data.dataset_root=./datasets/surge-20k
                    - trainer.accelerator=cpu
                    - trainer.devices=1
                codePath: src/eval.py
                codePathLocal: src/eval.py
                cpu_count: 4
                cpu_count_logical: 8
                disk:
                    /:
                        total: "254356226048"
                        used: "125564469248"
                email: benyoh73@gmail.com
                executable: /home/benjamin/Documents/work/Synthetizers-parameters-estimation/.venv/bin/python3
                git:
                    commit: baed96aa5d119d4df7b6151b420688691d26dcdd
                    remote: https://github.com/Hdandria/Synthetizers-parameters-estimation
                host: device-58.home
                memory:
                    total: "16629215232"
                os: Linux-6.16.10-200.fc42.x86_64-x86_64-with-glibc2.41
                program: /home/benjamin/Documents/work/Synthetizers-parameters-estimation/src/eval.py
                python: CPython 3.12.11
                root: ./outputs/eval-run/predictions
                startedAt: "2025-10-27T16:19:13.990419Z"
                writerId: feb93dq0mu5k5l2hgrl75zhatm8zbq1v
        m:
            - "1": trainer/global_step
              "6":
                - 3
              "7": []
            - "2": '*'
              "5": 1
              "6":
                - 1
              "7": []
        python_version: 3.12.11
        t:
            "1":
                - 1
                - 5
                - 50
                - 53
                - 106
            "2":
                - 1
                - 5
                - 50
                - 53
                - 106
            "3":
                - 2
                - 7
                - 15
                - 66
            "4": 3.12.11
            "5": 0.22.2
            "12": 0.22.2
            "13": linux-x86_64
callbacks:
    value:
        lr_monitor:
            _target_: lightning.pytorch.callbacks.LearningRateMonitor
            logging_interval: step
        model_checkpoint:
            _target_: lightning.pytorch.callbacks.ModelCheckpoint
            auto_insert_metric_name: false
            dirpath: ${paths.output_dir}/checkpoints
            every_n_epochs: null
            every_n_train_steps: null
            filename: epoch_{epoch:03d}
            mode: min
            monitor: null
            save_last: true
            save_on_train_epoch_end: null
            save_top_k: 1
            save_weights_only: false
            train_time_interval: null
            verbose: false
        model_summary:
            _target_: lightning.pytorch.callbacks.RichModelSummary
            max_depth: 2
        plot_pos_enc:
            _target_: src.utils.callbacks.PlotPositionalEncodingSimilarity
        plot_proj:
            _target_: src.utils.callbacks.PlotLearntProjection
        plot_proj_ii:
            _target_: src.utils.callbacks.PlotLearntProjection
        prediction_writer:
            _target_: src.utils.callbacks.PredictionWriter
            output_dir: ${paths.output_dir}/predictions
            write_interval: batch
        rich_progress_bar:
            _target_: lightning.pytorch.callbacks.RichProgressBar
ckpt_path:
    value: ./logs/dataset_20k_40k-2025-10-24_12-59-16/checkpoints/last.ckpt
data:
    value:
        _target_: src.data.surge_datamodule.SurgeDataModule
        batch_size: 128
        dataset_root: ./datasets/surge-20k
        num_workers: 11
        ot: true
        predict_file: test.h5
        use_saved_mean_and_variance: true
extras:
    value:
        enforce_tags: true
        float32_matmul_precision: high
        ignore_warnings: false
        print_config: true
model:
    value:
        _target_: src.models.surge_flow_matching_module.SurgeFlowMatchingModule
        cfg_dropout_rate: 0.1
        compile: true
        encoder:
            _target_: src.models.components.transformer.AudioSpectrogramTransformer
            d_model: 512
            input_channels: 2
            n_conditioning_outputs: 8
            n_heads: 8
            n_layers: 8
            patch_size: 16
            patch_stride: 10
            spec_shape:
                - 128
                - 401
        num_params: 92
        optimizer:
            _partial_: true
            _target_: torch.optim.Adam
            lr: 0.0001
            weight_decay: 0
        rectified_sigma_min: 0
        scheduler:
            _partial_: true
            _target_: torch.optim.lr_scheduler.CosineAnnealingLR
            T_max: ${trainer.max_steps}
            eta_min: ${mul:${model.optimizer.lr},1e-2}
        test_cfg_strength: 2
        test_sample_steps: 200
        validation_cfg_strength: 2
        validation_sample_steps: 50
        vector_field:
            _target_: src.models.components.transformer.ApproxEquivTransformer
            adaln_mode: basic
            conditioning_dim: ${model.encoder.d_model}
            d_ff: 512
            d_model: 512
            learn_pe: false
            learn_projection: true
            norm: layer
            num_heads: 8
            num_layers: 8
            num_tokens: ${model.vector_field.projection.num_tokens}
            outer_residual: false
            pe_penalty: 0
            pe_type: none
            projection:
                _target_: src.models.components.transformer.LearntProjection
                d_model: ${model.vector_field.d_model}
                d_token: ${model.vector_field.d_model}
                final_ffn: false
                initial_ffn: true
                num_params: ${model.num_params}
                num_tokens: 128
            projection_penalty: 0.01
            skip_first_norm: false
            time_encoding: sinusoidal
            zero_init: false
        warmup_steps: 0
model/params/non_trainable:
    value: 0
model/params/total:
    value: 39922688
model/params/trainable:
    value: 39922688
seed:
    value: null
tags:
    value:
        - dev
task_name:
    value: train
trainer:
    value:
        _target_: lightning.pytorch.trainer.Trainer
        accelerator: cpu
        check_val_every_n_epoch: null
        default_root_dir: ${paths.output_dir}
        deterministic: false
        devices: 1
        gradient_clip_val: 0.5
        log_every_n_steps: 100
        max_steps: 40000
        min_steps: 40000
        precision: 16-mixed
        val_check_interval: null
