#!/bin/bash
set -euo pipefail

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
ovhai job run \
  --name "${JOB_NAME}" \
  --flavor "${FLAVOR:-ai1-1-gpu}" \
  --gpu "${NUM_GPUS}" \
  --volume "${S3_BUCKET_DATASETS}@${DATASTORE_ALIAS}:/workspace/datasets-mount:ro" \
  --volume "${S3_BUCKET_OUTPUTS}@${DATASTORE_ALIAS}:/workspace/outputs:rw" \
  --env WANDB_API_KEY="${WANDB_API_KEY}" \
  --env PROJECT_ROOT=/workspace \
  --env MPLCONFIGDIR=/tmp/matplotlib \
  --env AWS_ACCESS_KEY_ID="${AWS_ACCESS_KEY_ID}" \
  --env AWS_SECRET_ACCESS_KEY="${AWS_SECRET_ACCESS_KEY}" \
  if [[ "$SKIP_BUILD" == false ]]; then
    echo -e "${BLUE}[*] Building Docker image...${RESET}"
    docker build -t synth-param-estimation:latest .
    echo -e "${GREEN}[+] Docker image built${RESET}"
  else
    echo -e "${YELLOW}[-] Skipping Docker build${RESET}"
  fi

  DOCKER_GPUS_OPT="--gpus all"
  [[ -n "${GPU_IDS_TRIMMED}" ]] && DOCKER_GPUS_OPT="--gpus device=${GPU_IDS_TRIMMED}"
  [[ -z "${GPU_IDS_TRIMMED}" && -n "${NUM_GPUS}" ]] && DOCKER_GPUS_OPT="--gpus ${NUM_GPUS}"

  # Build Hydra overrides for local
  HYDRA_OVERRIDES=("experiment=${EXPERIMENT_CONFIG}" "trainer.accelerator=gpu" "trainer.devices=${NUM_GPUS}")
  [[ -n "${DATA_NUM_WORKERS}" ]] && HYDRA_OVERRIDES+=("data.num_workers=${DATA_NUM_WORKERS}")

  echo -e "${BLUE}[*] Running training locally with Docker...${RESET}"
  echo -e "${CYAN}    GPUs: ${NUM_GPUS}${RESET}"
  [[ -n "${DATA_NUM_WORKERS}" ]] && echo -e "${CYAN}    Workers: ${DATA_NUM_WORKERS}${RESET}"
  # Extract and check dataset
  echo -e "${BLUE}[*] Checking dataset readability...${RESET}"
  echo -e "${CYAN}    Dataset path: ${DATASET_LOCAL_PATH}${RESET}"

  if [[ ! -d "$DATASET_LOCAL_PATH" ]]; then
    echo -e "${RED}Error: Dataset directory not found: ${DATASET_LOCAL_PATH}${RESET}"
    exit 1
  fi

  READ_CHECK=(python scripts/dataset/test_readability.py "$DATASET_LOCAL_PATH")
  if [[ "${DATASET_CHECK_VERBOSE}" == "true" ]]; then
    echo -e "${YELLOW}[debug] Dataset readability check running in verbose mode${RESET}"
  else
    ovhai job run \
      --name "${JOB_NAME}" \
      --flavor "${FLAVOR:-ai1-1-gpu}" \
      --gpu "${NUM_GPUS}" \
      --volume "${S3_BUCKET_DATASETS}@${DATASTORE_ALIAS}:/workspace/datasets-mount:ro" \
      --volume "${S3_BUCKET_OUTPUTS}@${DATASTORE_ALIAS}:/workspace/outputs:rw" \
      --env WANDB_API_KEY="${WANDB_API_KEY}" \
      --env PROJECT_ROOT=/workspace \
      --env MPLCONFIGDIR=/tmp/matplotlib \
      --env AWS_ACCESS_KEY_ID="${AWS_ACCESS_KEY_ID}" \
      --env AWS_SECRET_ACCESS_KEY="${AWS_SECRET_ACCESS_KEY}" \
      --env AWS_ENDPOINT_URL="${AWS_ENDPOINT_URL}" \
      --env AWS_DEFAULT_REGION="${AWS_DEFAULT_REGION:-gra}" \
      --env DATASET_CHECK_VERBOSE="${DATASET_CHECK_VERBOSE}" \
      --env DATASET_REMOTE_PATH="${DATASET_REMOTE_PATH}" \
      --env DATASET_DISPLAY_NAME="${DATASET_DISPLAY_NAME}" \
      --env HYDRA_OVERRIDES_STRING="${HYDRA_OVERRIDES_STRING}" \
      --env INSPECT_CONFIG="${INSPECT_CONFIG}" \
      $([ -n "${GPU_IDS_TRIMMED}" ] && echo "--env CUDA_VISIBLE_DEVICES=${GPU_IDS_TRIMMED}") \
      --unsecure-http \
      --output json \
      "${FULL_IMAGE}" \
      -- bash -lc "${REMOTE_SCRIPT}" \
      | tee /tmp/job_output.json
echo -e "${BLUE}[*] Configuring S3 datastore...${RESET}"
DATASTORE_ALIAS="s3-${OVH_REGION:-gra}"
if ! ovhai datastore list 2>/dev/null | grep -q "^${DATASTORE_ALIAS}"; then
  REGION_LOWER=$(echo "${OVH_REGION:-GRA}" | tr '[:upper:]' '[:lower:]')
  ovhai datastore add s3 "${DATASTORE_ALIAS}" "${AWS_ENDPOINT_URL}" "${REGION_LOWER}" \
    "${AWS_ACCESS_KEY_ID}" "${AWS_SECRET_ACCESS_KEY}" --store-credentials-locally
  echo -e "${GREEN}[+] S3 datastore added: ${DATASTORE_ALIAS}${RESET}"
else
  echo -e "${GREEN}[+] S3 datastore found: ${DATASTORE_ALIAS}${RESET}"
fi

# Get registry and bucket info from Terraform or fallback to env
if [[ -d terraform/.terraform ]]; then
  echo -e "${BLUE}[*] Reading configuration from Terraform...${RESET}"
  cd terraform
  REGISTRY_URL=$(terraform output -raw registry_url 2>/dev/null || echo "${DOCKER_REGISTRY}")
  S3_BUCKET_DATASETS=$(terraform output -raw s3_bucket_datasets 2>/dev/null || echo "${S3_BUCKET}")
  S3_BUCKET_OUTPUTS=$(terraform output -raw s3_bucket_outputs 2>/dev/null || echo "${S3_BUCKET_OUTPUTS}")
  cd ..
  echo -e "${GREEN}[+] Terraform configuration loaded${RESET}"
else
  echo -e "${YELLOW}[!] Terraform not initialized, using environment variables${RESET}"
  REGISTRY_URL="${DOCKER_REGISTRY}"
  S3_BUCKET_DATASETS="${S3_BUCKET}"
  S3_BUCKET_OUTPUTS="${S3_BUCKET_OUTPUTS}"
fi

echo -e "${CYAN}    Registry: ${REGISTRY_URL}${RESET}"
echo -e "${CYAN}    Datasets: ${S3_BUCKET_DATASETS}${RESET}"
echo -e "${CYAN}    Outputs: ${S3_BUCKET_OUTPUTS}${RESET}"
echo -e "${CYAN}    Dataset path (remote): ${DATASET_REMOTE_PATH}${RESET}"

HYDRA_OVERRIDES_STRING="${HYDRA_OVERRIDES_CLOUD[*]}"

REMOTE_SCRIPT=$(cat <<'EOF'
set -euo pipefail

if [[ -z "${DATASET_REMOTE_PATH:-}" ]]; then
  echo "ERROR: DATASET_REMOTE_PATH env is empty"
  exit 1
fi

if [[ -z "${HYDRA_OVERRIDES_STRING:-}" ]]; then
  echo "ERROR: HYDRA_OVERRIDES_STRING env is empty"
  exit 1
fi

DATASET_LABEL="${DATASET_DISPLAY_NAME:-<unknown>}"
echo "Dataset source (config): ${DATASET_LABEL}"
echo "Resolved dataset path: ${DATASET_REMOTE_PATH}"

if [[ ! -d "${DATASET_REMOTE_PATH}" ]]; then
  echo "ERROR: Dataset path not found: ${DATASET_REMOTE_PATH}"
  exit 1
fi

echo "Dataset directory contents:"
ls -lah "${DATASET_REMOTE_PATH}"

echo "Running dataset readability check..."
READ_CHECK=(python scripts/dataset/test_readability.py "${DATASET_REMOTE_PATH}")
if [[ "${DATASET_CHECK_VERBOSE:-false}" == "true" ]]; then
  echo "[debug] Dataset readability running in verbose mode"
else
  READ_CHECK+=(--quiet)
fi

if ! HDF5_VDS_PREFIX="/workspace/datasets-mount" "${READ_CHECK[@]}"; then
  echo "ERROR: Dataset readability check failed"
  echo "Hint: set DATASET_CHECK_VERBOSE=true to inspect details"
  exit 1
fi

echo "Dataset readability check passed"

cd /workspace

IFS=$' \t\n' read -r -a HYDRA_ARGS <<< "${HYDRA_OVERRIDES_STRING}"

if [[ "${INSPECT_CONFIG:-false}" == "true" ]]; then
  echo "Hydra resolved config (first 120 lines):"
  python src/train.py "${HYDRA_ARGS[@]}" data.dataset_root="${DATASET_REMOTE_PATH}" --cfg job --resolve | head -n 120
fi

python src/train.py "${HYDRA_ARGS[@]}" data.dataset_root="${DATASET_REMOTE_PATH}"
EOF
)

# Build and push image
IMAGE_TAG="$(echo "$EXPERIMENT_CONFIG" | tr '/' '-')-$(date +%Y%m%d-%H%M%S)"
FULL_IMAGE="${REGISTRY_URL}/synth-param-estimation:${IMAGE_TAG}"

[[ -n "${DOCKER_USERNAME:-}" && -n "${DOCKER_PASSWORD:-}" ]] && \
  echo "${DOCKER_PASSWORD}" | docker login --username "${DOCKER_USERNAME}" --password-stdin 2>/dev/null || true

if [[ "$SKIP_BUILD" == false ]]; then
  echo -e "${BLUE}[*] Building and pushing Docker image...${RESET}"
  echo -e "${CYAN}    Image: ${FULL_IMAGE}${RESET}"
  docker build -t "$FULL_IMAGE" .
  docker push "$FULL_IMAGE"
  echo -e "${GREEN}[+] Docker image pushed${RESET}"
else
  echo -e "${YELLOW}[-] Skipping Docker build and push${RESET}"
fi


# Submit job
echo -e "${BLUE}[*] Submitting job to OVH AI Training...${RESET}"
JOB_NAME="$(echo "$EXPERIMENT_CONFIG" | tr '/' '-')-$(date +%s)"
echo -e "${CYAN}    Job name: ${JOB_NAME}${RESET}"
echo -e "${CYAN}    Flavor: ${FLAVOR:-ai1-1-gpu}${RESET}"
echo -e "${CYAN}    GPUs: ${NUM_GPUS}${RESET}"
[[ -n "${DATA_NUM_WORKERS}" ]] && echo -e "${CYAN}    Workers: ${DATA_NUM_WORKERS}${RESET}"

ovhai job run \
  --name "${JOB_NAME}" \
  --flavor "${FLAVOR:-ai1-1-gpu}" \
  --gpu "${NUM_GPUS}" \
  --volume "${S3_BUCKET_DATASETS}@${DATASTORE_ALIAS}:/workspace/datasets-mount:ro" \
  --volume "${S3_BUCKET_OUTPUTS}@${DATASTORE_ALIAS}:/workspace/outputs:rw" \
  --env WANDB_API_KEY="${WANDB_API_KEY}" \
  --env PROJECT_ROOT=/workspace \
  --env MPLCONFIGDIR=/tmp/matplotlib \
  --env AWS_ACCESS_KEY_ID="${AWS_ACCESS_KEY_ID}" \
  --env AWS_SECRET_ACCESS_KEY="${AWS_SECRET_ACCESS_KEY}" \
  --env AWS_ENDPOINT_URL="${AWS_ENDPOINT_URL}" \
  --env AWS_DEFAULT_REGION="${AWS_DEFAULT_REGION:-gra}" \
  --env DATASET_CHECK_VERBOSE="${DATASET_CHECK_VERBOSE}" \
  $([ -n "${GPU_IDS_TRIMMED}" ] && echo "--env CUDA_VISIBLE_DEVICES=${GPU_IDS_TRIMMED}") \
  --unsecure-http \
  --output json \
  "${FULL_IMAGE}" \
  -- bash -c "\
      if [ -d /workspace/datasets-mount/datasets ]; then \
        MOUNT_BASE='/workspace/datasets-mount/datasets'; \
      elif [ -d /workspace/datasets-mount ]; then \
        MOUNT_BASE='/workspace/datasets-mount'; \
      else \
        echo 'ERROR: datasets mount not found'; exit 1; \
      fi && \
      CONFIG_FILE='configs/experiment/${EXPERIMENT_CONFIG}.yaml' && \
      DATASET_REL_PATH=\$(grep -oP 'dataset_root:\s*\K.*' \"\${CONFIG_FILE}\" | tr -d \"'\\\"\" | xargs) && \
      if [ -z \"\${DATASET_REL_PATH}\" ]; then \
        DATA_OVERRIDE=\$(grep -oP 'override /data:\s*\K.*' \"\${CONFIG_FILE}\" | head -1) && \
        if [ -n \"\${DATA_OVERRIDE}\" ]; then \
          DATA_CONFIG=\"configs/data/\${DATA_OVERRIDE}.yaml\" && \
          if [ -f \"\${DATA_CONFIG}\" ]; then \
            DATASET_REL_PATH=\$(grep -oP 'dataset_root:\s*\K.*' \"\${DATA_CONFIG}\" | tr -d \"'\\\"\" | xargs); \
          fi; \
        fi; \
      fi && \
      if [ -z \"\${DATASET_REL_PATH}\" ]; then \
        echo 'ERROR: Could not extract dataset_root from config'; exit 1; \
      fi && \
      DATASET_NAME=\$(basename \"\${DATASET_REL_PATH}\") && \
      DATASET_PATH=\"\${MOUNT_BASE}/\${DATASET_NAME}\" && \
      echo \"Config dataset_root: \${DATASET_REL_PATH}\" && \
      echo \"Extracted dataset name: \${DATASET_NAME}\" && \
      echo \"Resolved absolute path: \${DATASET_PATH}\" && \
      echo \"Checking dataset directory...\" && \
      ls -lah \"\${DATASET_PATH}/\" && \
      echo \"Running dataset readability check...\" && \
      # Ensure VDS relative filenames like 'datasets/...' resolve correctly on OVH mount
      export HDF5_VDS_PREFIX=\"/workspace/datasets-mount\" && \
      if [ \"\${DATASET_CHECK_VERBOSE:-}\" = \"true\" ]; then QUIET_FLAG=; else QUIET_FLAG=--quiet; fi && \
      python scripts/dataset/test_readability.py \"\${DATASET_PATH}\" \"\${QUIET_FLAG}\" && \
      echo \"Dataset readability check passed\" && \
      cd /workspace && \
      if [ \"\${INSPECT_CONFIG:-}\" = \"true\" ]; then \
        echo \"Resolved Hydra config (truncated):\" && \
        python src/train.py ${HYDRA_OVERRIDES_CLOUD[*]} data.dataset_root=\"\${DATASET_PATH}\" --cfg job --resolve | head -n 120; \
      fi && \
      python src/train.py ${HYDRA_OVERRIDES_CLOUD[*]} data.dataset_root=\"\${DATASET_PATH}\"\
    " \
  | tee /tmp/job_output.json

JOB_ID=$(jq -r '.id // .uuid // empty' /tmp/job_output.json)
[[ -z "$JOB_ID" ]] && { echo -e "${RED}Error: Failed to get job ID${RESET}"; exit 1; }

echo ""
echo -e "${GREEN}${BOLD}[+] Job submitted successfully!${RESET}"
echo -e "${CYAN}------------------------------------------------------------${RESET}"
echo -e "${BOLD}Job ID:${RESET}    ${GREEN}${JOB_ID}${RESET}"
echo -e "${BOLD}Monitor:${RESET}   ${BLUE}./scripts/ovh/status.sh ${JOB_ID}${RESET}"
echo -e "${BOLD}Logs:${RESET}      ${BLUE}./scripts/ovh/logs.sh ${JOB_ID}${RESET}"
echo -e "${CYAN}------------------------------------------------------------${RESET}"

[[ "$STREAM_LOGS" == true ]] && { echo -e "${BLUE}[*] Streaming logs...${RESET}"; sleep 10; ovhai job logs "$JOB_ID" --follow; }
