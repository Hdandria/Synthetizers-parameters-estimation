# Audio-to-DAW

> Clone of [ben hayes](https://github.com/ben-hayes/synth-permutations) repository

Neural network models for inferring audio synthesizer parameters from audio signals.

## Overview

This project trains models to predict synthesizer parameters from audio recordings. Given an audio clip generated by a synthesizer, the model learns to estimate the parameter settings that produced it.

## Documentation

- [SETUP.md](SETUP.md) - Environment setup and installation
- [USAGE.md](USAGE.md) - Training, evaluation, and dataset generation
- [CONFIGURATION.md](CONFIGURATION.md) - Configuration system overview
- [docker/README.md](docker/README.md) - Docker setup for GPU training

## Project Structure

```
audio-to-daw/
├── configs/          # Hydra configuration files
│   ├── data/        # Dataset configurations
│   ├── model/       # Model architectures
│   ├── trainer/     # Training configurations
│   └── experiment/  # Full experiment configs
├── src/
│   ├── data/        # Data modules and dataset generation
│   ├── models/      # Model implementations
│   ├── train.py     # Training script
│   └── eval.py      # Evaluation script
├── scripts/         # Utility scripts
├── docker/          # Docker configuration and helper scripts
├── tests/           # Unit tests
├── Dockerfile       # Docker image definition
└── docker-compose.yml # Docker service orchestration
```

## Supported Datasets

> Uniquement testé surge XT pour l'instant

- **Surge XT** - VST synthesizer with comprehensive parameter control
- **KSIN** - K-oscillator sine wave dataset with permutation symmetry
- **KOSC** - K-oscillator dataset with complex waveforms
- **NSynth** - Google's neural audio synthesis dataset
- **FSD50K** - FreeSound Dataset for audio tagging

## Supported Models

- **FFN** - Feed-forward neural network
- **Flow Matching** - Generative model using continuous normalizing flows
- **FlowVAE** - Variational autoencoder with flow-based decoder

## Quick Start

### Option 1: Docker (Recommended)
For GPU training with minimal setup:

```bash
# Build and run with Docker
docker-compose build
./docker/run_training.sh surge/baseline
```

See [docker/README.md](docker/README.md) for detailed Docker setup instructions.

### Option 2: Local Installation
For development and customization:

```bash
# Install dependencies
uv pip install -r requirements.txt

# Run training
python src/train.py experiment=surge/baseline
```

See [SETUP.md](SETUP.md) for detailed installation instructions.

## Requirements

- Python 3.10+
- PyTorch with GPU support recommended
- VST3 plugins (for dataset generation with Surge XT)
- Docker + NVIDIA Container Toolkit (for Docker setup)