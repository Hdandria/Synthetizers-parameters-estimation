# Audio-to-DAW

Neural network models for inferring audio synthesizer parameters from audio signals.

## Overview

This project trains models to predict synthesizer parameters from audio recordings. Given an audio clip generated by a synthesizer, the model learns to estimate the parameter settings that produced it.

**Key features:**
- Support for multiple synthesizers (Surge XT, KSIN, KOSC)
- Multiple model architectures (Feed-Forward Networks, Flow Matching, VAE)
- VST plugin integration for dataset generation
- PyTorch Lightning training framework
- Hydra configuration system

## Quick Start

**Installation:**
```bash
pip install -r requirements.txt
```

**Train a model:**
```bash
python src/train.py data=surge model=surge_ffn
```

**Evaluate a model:**
```bash
python src/eval.py ckpt_path=path/to/checkpoint.ckpt
```

## Documentation

- [SETUP.md](SETUP.md) - Environment setup and installation
- [USAGE.md](USAGE.md) - Training, evaluation, and dataset generation
- [CONFIGURATION.md](CONFIGURATION.md) - Configuration system overview

## Project Structure

```
audio-to-daw/
├── configs/          # Hydra configuration files
│   ├── data/        # Dataset configurations
│   ├── model/       # Model architectures
│   ├── trainer/     # Training configurations
│   └── experiment/  # Full experiment configs
├── src/
│   ├── data/        # Data modules and dataset generation
│   ├── models/      # Model implementations
│   ├── train.py     # Training script
│   └── eval.py      # Evaluation script
├── scripts/         # Utility scripts
└── tests/           # Unit tests
```

## Supported Datasets

- **Surge XT** - VST synthesizer with comprehensive parameter control
- **KSIN** - K-oscillator sine wave dataset with permutation symmetry
- **KOSC** - K-oscillator dataset with complex waveforms
- **NSynth** - Google's neural audio synthesis dataset
- **FSD50K** - FreeSound Dataset for audio tagging

## Supported Models

- **FFN** - Feed-forward neural network
- **Flow Matching** - Generative model using continuous normalizing flows
- **FlowVAE** - Variational autoencoder with flow-based decoder

## Requirements

- Python 3.10+
- PyTorch with GPU support recommended
- VST3 plugins (for dataset generation with Surge XT)

## Citation

If you use this code in your research, please cite:

```
[Citation information to be added]
```

## License

[License information to be added]

